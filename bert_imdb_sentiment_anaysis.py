# -*- coding: utf-8 -*-
"""BERT IMDB_Sentiment_Anaysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wQDtRGcMJTapX-EiNdgemZnF_896CTjM
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries
import tensorflow as tf
import os
!pip install -q opendatasets
import opendatasets as od
import pandas as pd
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt


import numpy as np
import pandas as pd
import random
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from collections import Counter
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score,precision_recall_fscore_support
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set_context('notebook',font_scale=1.25)
from wordcloud import WordCloud,STOPWORDS
import warnings
warnings.filterwarnings('ignore')
from IPython.core.display import HTML,display
import re
import timeit
import gc

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_hub as hub
from tensorflow.keras.optimizers.schedules import PolynomialDecay
from tensorflow.keras import mixed_precision

!pip install datasets --quiet
!pip install transformers

import transformers
from datasets import load_dataset
from transformers import AutoTokenizer,DataCollatorWithPadding
from transformers import TFAutoModelForSequenceClassification

# function ClickConnect() {
# console.log("Working");
# document
#   .querySelector('#top-toolbar > colab-connect-button')
#   .shadowRoot.querySelector('#connect')
#   .click()
# }
# setInterval(ClickConnect, 60000)

data=load_dataset('csv',data_files='/content/drive/MyDrive/movie.csv')
data

# converting to lowercase
def lowercase_text(example):
    return{'text':example['text'].lower()}
data=data.map(lowercase_text)

checkpoint='bert-base-uncased'
# checkpoint='roberta-large-mnli'

tokenizer=AutoTokenizer.from_pretrained(checkpoint)

#defining the tokenization function
def tokenize_function(example):
    return tokenizer(example['text'],truncation=True)

tokenized_dataset=data.map(tokenize_function,batched=True)

#policy to be used while batching
data_collator=DataCollatorWithPadding(tokenizer=tokenizer,return_tensors='tf')

tokenized_splitted_dataset=tokenized_dataset['train'].train_test_split(test_size=0.2)
test_set_lenght=len(tokenized_splitted_dataset['test']['label'])
tokenized_splitted_dataset

tf_train_dataset = tokenized_splitted_dataset["train"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["label"],
    shuffle=True,
    collate_fn=data_collator,
    batch_size=8,
).prefetch(tf.data.AUTOTUNE)

tf_validation_dataset = tokenized_splitted_dataset["test"].to_tf_dataset(
    columns=["attention_mask", "input_ids", "token_type_ids"],
    label_cols=["label"],
    shuffle=False,
    collate_fn=data_collator,
    batch_size=8,
).prefetch(tf.data.AUTOTUNE)

model_6 = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=1)

epochs=1
mini_batches=int(0.2*len(tf_train_dataset))
num_steps=epochs*mini_batches
learning_rate_schedule=PolynomialDecay(
    initial_learning_rate=5e-5,
    decay_steps=num_steps,
    end_learning_rate=0.0,
)

model_6.compile(
    loss=keras.losses.BinaryCrossentropy(from_logits=True),
    optimizer=keras.optimizers.Adam(learning_rate=learning_rate_schedule),
    metrics=['accuracy']
)

model_6_history=model_6.fit(
    tf_train_dataset,
    steps_per_epoch=int(0.2*len(tf_train_dataset)),
    epochs=epochs,
    validation_data=tf_validation_dataset
)

start_time=timeit.default_timer()
model_6_pred_logits=model_6.predict(tf_validation_dataset)
model_6_pred=tf.round(tf.nn.sigmoid(model_6_pred_logits['logits']))
end_time=timeit.default_timer()
time_taken_per_instance=(end_time-start_time)/test_set_lenght
model_6_results=binary_clf_evaluation(tokenized_splitted_dataset['test']['label'],model_6_pred,time_taken_per_instance)
display_results(model_6_results)

loss, accuracy = model.evaluate(test_ds)
print("Loss: ", loss)
print("Accuracy: ", accuracy)

while True:pass

"""# New Section"""